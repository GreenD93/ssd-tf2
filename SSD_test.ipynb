{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from ssd.ssd_vgg16 import create_ssd_vgg16\n",
    "from ssd.ssd_mobilenetv1 import create_ssd_mobilenetv1\n",
    "from ssd.ssd_mobilenetv1_lite import create_ssd_mobilenetv1_lite\n",
    "from ssd.ssd_mobilenetv2_lite import create_ssd_mobilenetv2_lite\n",
    "from ssd.pre_ssd_mobilenetv1_lite import create_pre_ssd_mobilenetv1_lite\n",
    "from ssd.pre_ssd_mobilenetv2_lite import create_pre_ssd_mobilenetv2_lite\n",
    "from ssd.ssd import init_ssd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "from voc_data import create_batch_generator\n",
    "from anchor import generate_default_boxes\n",
    "from losses import create_losses\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from anchor import generate_default_boxes\n",
    "from box_utils import decode, compute_nms\n",
    "from voc_data import create_batch_generator\n",
    "from image_utils import ImageVisualizer\n",
    "from losses import create_losses\n",
    "from PIL import Image\n",
    "\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 epoch당 7-8시간 소요\n",
    "\n",
    "os.makedirs(OUTPUT_IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DETECTS_DIR, exist_ok=True)\n",
    "\n",
    "visualizer = ImageVisualizer(IDX_TO_NAME, save_dir=OUTPUT_IMAGES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'pre_ssd300-mobilenetv2'\n",
    "CHECKPOINT_DIR = 'checkpoint/pre_mobilenetv2_lite'\n",
    "CHECKPOINT_PATH = 'checkpoint/pre_mobilenetv2_lite/ssd_epoch_200.h5'\n",
    "\n",
    "default_boxes = generate_default_boxes(INFO[ARCH])\n",
    "ssd = create_pre_ssd_mobilenetv2_lite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> load_weights\n"
     ]
    }
   ],
   "source": [
    "pretrained_type = 'specified'\n",
    "checkpoint_path = CHECKPOINT_PATH\n",
    "\n",
    "net = init_ssd(ssd, pretrained_type, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator, info = create_batch_generator(\n",
    "    DATA_DIR, DATA_YEAR, default_boxes,\n",
    "    SIZE, batch_size=BATCH_SIZE, num_batches=-1, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(confs, locs, default_boxes):\n",
    "\n",
    "    confs = tf.math.softmax(confs, axis=-1)\n",
    "    classes = tf.math.argmax(confs, axis=-1)\n",
    "    scores = tf.math.reduce_max(confs, axis=-1)\n",
    "\n",
    "    boxes = decode(default_boxes, locs)\n",
    "\n",
    "    out_boxes = []\n",
    "    out_labels = []\n",
    "    out_scores = []\n",
    "\n",
    "    for c in range(1, NUM_CLASSES):\n",
    "        cls_scores = confs[:, c]\n",
    "\n",
    "        score_idx = cls_scores > 0.7\n",
    "\n",
    "        cls_boxes = boxes[score_idx]\n",
    "        cls_scores = cls_scores[score_idx]\n",
    "\n",
    "        nms_idx = compute_nms(cls_boxes, cls_scores, NMS_THRESHOLD, 200)\n",
    "        cls_boxes = tf.gather(cls_boxes, nms_idx)\n",
    "        cls_scores = tf.gather(cls_scores, nms_idx)\n",
    "        cls_labels = [c] * cls_boxes.shape[0]\n",
    "\n",
    "        out_boxes.append(cls_boxes)\n",
    "        out_labels.extend(cls_labels)\n",
    "        out_scores.append(cls_scores)\n",
    "\n",
    "    out_boxes = tf.concat(out_boxes, axis=0)\n",
    "    out_scores = tf.concat(out_scores, axis=0)\n",
    "\n",
    "    boxes = tf.clip_by_value(out_boxes, 0.0, 1.0).numpy()\n",
    "    classes = np.array(out_labels)\n",
    "    scores = out_scores.numpy()\n",
    "\n",
    "    return boxes, classes, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New ver.(Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing...: 612images [13:26,  1.32s/images]                     \n"
     ]
    }
   ],
   "source": [
    "for i, (arr_filename, arr_tf_imgs, arr_gt_confs, arr_gt_locs) in enumerate(tqdm(batch_generator, total= info['length'] // BATCH_SIZE, \n",
    "                                                             desc='Testing...', unit='images')):\n",
    "    arr_confs, arr_locs = net(arr_tf_imgs)\n",
    "\n",
    "    # 각 이미지 별\n",
    "    for confs, locs, filename in zip(arr_confs, arr_locs, arr_filename):\n",
    "        \n",
    "        boxes, classes, scores = predict(confs, locs, default_boxes)\n",
    "\n",
    "        filename = filename.numpy().decode()\n",
    "        original_image = Image.open(\n",
    "            os.path.join(info['image_dir'], '{}.jpg'.format(filename)))\n",
    "        boxes *= original_image.size * 2\n",
    "        \n",
    "        log_file = os.path.join('outputs/detects_mobilenetv1', '{}.txt')\n",
    "        \n",
    "        for cls, box, score in zip(classes, boxes, scores):\n",
    "            cls_name = info['idx_to_name'][cls - 1]\n",
    "            with open(log_file.format(cls_name), 'a') as f:\n",
    "                f.write('{} {} {} {} {} {}\\n'.format(\n",
    "                    filename,\n",
    "                    score,\n",
    "                    *[coord for coord in box]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old ver.(Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgs, default_boxes):\n",
    "    confs, locs = net(imgs)\n",
    "\n",
    "    confs = tf.squeeze(confs, 0)\n",
    "    locs = tf.squeeze(locs, 0)\n",
    "\n",
    "    confs = tf.math.softmax(confs, axis=-1)\n",
    "    classes = tf.math.argmax(confs, axis=-1)\n",
    "    scores = tf.math.reduce_max(confs, axis=-1)\n",
    "\n",
    "    boxes = decode(default_boxes, locs)\n",
    "\n",
    "    out_boxes = []\n",
    "    out_labels = []\n",
    "    out_scores = []\n",
    "\n",
    "    for c in range(1, NUM_CLASSES):\n",
    "        cls_scores = confs[:, c]\n",
    "\n",
    "        score_idx = cls_scores > CLS_SCORE\n",
    "\n",
    "        cls_boxes = boxes[score_idx]\n",
    "        cls_scores = cls_scores[score_idx]\n",
    "\n",
    "        nms_idx = compute_nms(cls_boxes, cls_scores, NMS_THRESHOLD, 200)\n",
    "        cls_boxes = tf.gather(cls_boxes, nms_idx)\n",
    "        cls_scores = tf.gather(cls_scores, nms_idx)\n",
    "        cls_labels = [c] * cls_boxes.shape[0]\n",
    "\n",
    "        out_boxes.append(cls_boxes)\n",
    "        out_labels.extend(cls_labels)\n",
    "        out_scores.append(cls_scores)\n",
    "\n",
    "    out_boxes = tf.concat(out_boxes, axis=0)\n",
    "    out_scores = tf.concat(out_scores, axis=0)\n",
    "\n",
    "    boxes = tf.clip_by_value(out_boxes, 0.0, 1.0).numpy()\n",
    "    classes = np.array(out_labels)\n",
    "    scores = out_scores.numpy()\n",
    "\n",
    "    return boxes, classes, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset'\n",
    "batch_generator, info = create_batch_generator(\n",
    "    DATA_DIR, DATA_YEAR, default_boxes,\n",
    "    SIZE, 1, -1, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (filename, imgs, gt_confs, gt_locs) in enumerate(\n",
    "    tqdm(batch_generator, total=info['length'],\n",
    "         desc='Testing...', unit='images')):\n",
    "    boxes, classes, scores = predict(imgs, default_boxes)\n",
    "    filename = filename.numpy()[0].decode()\n",
    "    original_image = Image.open(\n",
    "        os.path.join(info['image_dir'], '{}.jpg'.format(filename)))\n",
    "    boxes *= original_image.size * 2\n",
    "    \n",
    "#     visualizer.save_image(\n",
    "#         original_image, boxes, classes, '{}.jpg'.format(filename))\n",
    "\n",
    "    log_file = os.path.join('outputs/detects', '{}.txt')\n",
    "\n",
    "    for cls, box, score in zip(classes, boxes, scores):\n",
    "        cls_name = info['idx_to_name'][cls - 1]\n",
    "        with open(log_file.format(cls_name), 'a') as f:\n",
    "            f.write('{} {} {} {} {} {}\\n'.format(\n",
    "                filename,\n",
    "                score,\n",
    "                *[coord for coord in box]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
